"""
ê²½ëŸ‰ ìŠ¤ì¼€ì¼ëŸ¬ ìœ í‹¸ë¦¬í‹°

pytorch-forecasting ì—†ì´ JSON íŒŒë¼ë¯¸í„°ë§Œìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ì„œë¹™ í™˜ê²½ì—ì„œ ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

Usage:
    from src.utils.lightweight_scaler import LightweightScaler
    
    scaler = LightweightScaler.from_json("checkpoints/scaler_params.json")
    scaled_value = scaler.transform(raw_value, group_id="Corn")
    original_value = scaler.inverse_transform(scaled_value, group_id="Corn")
"""

import json
import numpy as np
from typing import Union, Optional, Dict, Any
from pathlib import Path


class LightweightScaler:
    """
    ê²½ëŸ‰ ìŠ¤ì¼€ì¼ëŸ¬: JSON íŒŒë¼ë¯¸í„°ë§Œìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ ìˆ˜í–‰
    
    pytorch-forecastingì˜ GroupNormalizer ë™ì‘ì„ ì¬í˜„í•˜ì§€ë§Œ,
    ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ì—†ì´ numpyë§Œìœ¼ë¡œ êµ¬í˜„
    """
    
    def __init__(self, scaler_params: Dict[str, Any]):
        """
        Args:
            scaler_params: extract_scaler_params.pyë¡œ ì¶”ì¶œí•œ JSON íŒŒë¼ë¯¸í„°
        """
        self.params = scaler_params
        self.transformation = scaler_params['metadata'].get('transformation', 'softplus')
        self.groups = scaler_params['metadata'].get('groups', [])
        self.target = scaler_params['metadata'].get('target', 'close')
        
        self.normalizer_params = scaler_params.get('normalizer_params', {})
        self.center = self.normalizer_params.get('center')
        self.scale = self.normalizer_params.get('scale')
        self.group_statistics = self.normalizer_params.get('group_statistics', {})
        
        print(f"âœ… LightweightScaler initialized")
        print(f"   Transformation: {self.transformation}")
        print(f"   Groups: {self.groups}")
        print(f"   Target: {self.target}")
    
    @classmethod
    def from_json(cls, json_path: str) -> 'LightweightScaler':
        """
        JSON íŒŒì¼ì—ì„œ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        
        Args:
            json_path: scaler_params.json íŒŒì¼ ê²½ë¡œ
            
        Returns:
            LightweightScaler ì¸ìŠ¤í„´ìŠ¤
        """
        with open(json_path, 'r', encoding='utf-8') as f:
            scaler_params = json.load(f)
        
        return cls(scaler_params)
    
    def softplus(self, x: Union[float, np.ndarray]) -> Union[float, np.ndarray]:
        """
        Softplus ë³€í™˜: log(1 + exp(x))
        
        pytorch-forecastingì˜ GroupNormalizerì—ì„œ ì‚¬ìš©í•˜ëŠ” ë³€í™˜
        """
        x = np.asarray(x)
        # ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ í° ê°’ì€ linear approximation
        return np.where(x > 20, x, np.log1p(np.exp(x)))
    
    def inverse_softplus(self, y: Union[float, np.ndarray]) -> Union[float, np.ndarray]:
        """
        Softplus ì—­ë³€í™˜: log(exp(y) - 1)
        """
        y = np.asarray(y)
        # ìˆ˜ì¹˜ ì•ˆì •ì„±
        return np.where(y > 20, y, np.log(np.expm1(y)))
    
    def transform(
        self, 
        value: Union[float, np.ndarray], 
        group_id: Optional[str] = None,
        use_center: bool = True,
        use_scale: bool = True
    ) -> Union[float, np.ndarray]:
        """
        ì›ë³¸ ê°’ì„ ìŠ¤ì¼€ì¼ë§ëœ ê°’ìœ¼ë¡œ ë³€í™˜
        
        Args:
            value: ì›ë³¸ ê°’
            group_id: ê·¸ë£¹ ID (GroupNormalizer ì‚¬ìš© ì‹œ)
            use_center: ì¤‘ì‹¬í™” ì ìš© ì—¬ë¶€
            use_scale: ìŠ¤ì¼€ì¼ë§ ì ìš© ì—¬ë¶€
            
        Returns:
            ìŠ¤ì¼€ì¼ë§ëœ ê°’
        """
        value = np.asarray(value)
        
        # 1. Transformation ì ìš© (softplus ë“±)
        if self.transformation == 'softplus':
            value = self.softplus(value)
        elif self.transformation == 'log':
            value = np.log1p(value)
        elif self.transformation == 'log1p':
            value = np.log1p(value)
        # 'none'ì´ë‚˜ Noneì¸ ê²½ìš° ë³€í™˜ ì—†ìŒ
        
        # 2. ì •ê·œí™” (center & scale)
        if self.center is not None and use_center:
            if isinstance(self.center, (list, np.ndarray)) and len(self.center) > 0:
                center_val = self.center[0] if len(self.center) == 1 else self.center
                value = value - center_val
        
        if self.scale is not None and use_scale:
            if isinstance(self.scale, (list, np.ndarray)) and len(self.scale) > 0:
                scale_val = self.scale[0] if len(self.scale) == 1 else self.scale
                # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                scale_val = np.where(np.abs(scale_val) < 1e-8, 1.0, scale_val)
                value = value / scale_val
        
        # 3. ê·¸ë£¹ë³„ í†µê³„ ì ìš© (ìˆëŠ” ê²½ìš°)
        if group_id and self.group_statistics:
            group_key = str(group_id)
            if group_key in self.group_statistics:
                group_stats = self.group_statistics[group_key]
                if 'mean' in group_stats:
                    value = value - group_stats['mean']
                if 'std' in group_stats:
                    std_val = group_stats['std']
                    std_val = std_val if abs(std_val) > 1e-8 else 1.0
                    value = value / std_val
        
        return value if isinstance(value, np.ndarray) else float(value)
    
    def inverse_transform(
        self,
        scaled_value: Union[float, np.ndarray],
        group_id: Optional[str] = None,
        use_center: bool = True,
        use_scale: bool = True
    ) -> Union[float, np.ndarray]:
        """
        ìŠ¤ì¼€ì¼ë§ëœ ê°’ì„ ì›ë³¸ ê°’ìœ¼ë¡œ ì—­ë³€í™˜
        
        Args:
            scaled_value: ìŠ¤ì¼€ì¼ë§ëœ ê°’
            group_id: ê·¸ë£¹ ID
            use_center: ì¤‘ì‹¬í™” ì—­ë³€í™˜ ì—¬ë¶€
            use_scale: ìŠ¤ì¼€ì¼ ì—­ë³€í™˜ ì—¬ë¶€
            
        Returns:
            ì›ë³¸ ê°’
        """
        value = np.asarray(scaled_value)
        
        # 1. ê·¸ë£¹ë³„ í†µê³„ ì—­ë³€í™˜ (ìˆëŠ” ê²½ìš°)
        if group_id and self.group_statistics:
            group_key = str(group_id)
            if group_key in self.group_statistics:
                group_stats = self.group_statistics[group_key]
                if 'std' in group_stats:
                    value = value * group_stats['std']
                if 'mean' in group_stats:
                    value = value + group_stats['mean']
        
        # 2. ì •ê·œí™” ì—­ë³€í™˜ (scale & center)
        if self.scale is not None and use_scale:
            if isinstance(self.scale, (list, np.ndarray)) and len(self.scale) > 0:
                scale_val = self.scale[0] if len(self.scale) == 1 else self.scale
                value = value * scale_val
        
        if self.center is not None and use_center:
            if isinstance(self.center, (list, np.ndarray)) and len(self.center) > 0:
                center_val = self.center[0] if len(self.center) == 1 else self.center
                value = value + center_val
        
        # 3. Transformation ì—­ë³€í™˜
        if self.transformation == 'softplus':
            value = self.inverse_softplus(value)
        elif self.transformation in ['log', 'log1p']:
            value = np.expm1(value)
        
        return value if isinstance(value, np.ndarray) else float(value)
    
    def get_config(self) -> Dict[str, Any]:
        """
        ìŠ¤ì¼€ì¼ëŸ¬ ì„¤ì • ì •ë³´ ë°˜í™˜
        """
        return {
            'transformation': self.transformation,
            'groups': self.groups,
            'target': self.target,
            'has_center': self.center is not None,
            'has_scale': self.scale is not None,
            'num_groups': len(self.group_statistics),
            'feature_columns': self.params.get('feature_columns', {}),
            'dataset_config': self.params.get('dataset_config', {})
        }
    
    def summary(self):
        """
        ìŠ¤ì¼€ì¼ëŸ¬ ì •ë³´ ì¶œë ¥
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š LightweightScaler Summary")
        print("=" * 60)
        
        config = self.get_config()
        print(f"Target: {config['target']}")
        print(f"Transformation: {config['transformation']}")
        print(f"Groups: {config['groups']}")
        print(f"Center: {'âœ“' if config['has_center'] else 'âœ—'}")
        print(f"Scale: {'âœ“' if config['has_scale'] else 'âœ—'}")
        print(f"Group Statistics: {config['num_groups']} groups")
        
        dataset_config = config.get('dataset_config', {})
        print(f"\nDataset Configuration:")
        print(f"  Max Encoder Length: {dataset_config.get('max_encoder_length')}")
        print(f"  Max Prediction Length: {dataset_config.get('max_prediction_length')}")
        
        feature_cols = config.get('feature_columns', {})
        print(f"\nFeature Columns:")
        print(f"  Time-varying Known Reals: {len(feature_cols.get('time_varying_known_reals', []))}")
        print(f"  Time-varying Unknown Reals: {len(feature_cols.get('time_varying_unknown_reals', []))}")
        print(f"  Static Categoricals: {len(feature_cols.get('static_categoricals', []))}")
        
        print("=" * 60 + "\n")


def example_usage():
    """
    ì‚¬ìš© ì˜ˆì‹œ
    """
    print("=" * 60)
    print("ğŸ”§ LightweightScaler Usage Example")
    print("=" * 60 + "\n")
    
    # 1. JSONì—ì„œ ë¡œë“œ
    json_path = "checkpoints/scaler_params.json"
    
    if not Path(json_path).exists():
        print(f"âš ï¸  Example file not found: {json_path}")
        print("   Please run extract_scaler_params.py first:")
        print("   python scripts/ops/extract_scaler_params.py --input checkpoints/enhanced_tft_v1_preprocessing.pkl --output checkpoints/scaler_params.json")
        return
    
    scaler = LightweightScaler.from_json(json_path)
    scaler.summary()
    
    # 2. ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª Transform Test:")
    raw_price = 450.5
    print(f"   Raw Price: {raw_price}")
    
    scaled = scaler.transform(raw_price, group_id="Corn")
    print(f"   Scaled: {scaled:.6f}")
    
    inverse = scaler.inverse_transform(scaled, group_id="Corn")
    print(f"   Inverse: {inverse:.6f}")
    
    error = abs(raw_price - inverse)
    print(f"   Reconstruction Error: {error:.8f}")
    
    if error < 1e-6:
        print("   âœ… Perfect reconstruction!")
    else:
        print("   âš ï¸  Some numerical error (expected with transformations)")
    
    # 3. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ§ª Batch Transform Test:")
    raw_prices = np.array([450.5, 455.0, 460.2, 448.3, 452.1])
    print(f"   Raw Prices: {raw_prices}")
    
    scaled_batch = scaler.transform(raw_prices, group_id="Corn")
    print(f"   Scaled: {scaled_batch}")
    
    inverse_batch = scaler.inverse_transform(scaled_batch, group_id="Corn")
    print(f"   Inverse: {inverse_batch}")
    
    batch_error = np.max(np.abs(raw_prices - inverse_batch))
    print(f"   Max Reconstruction Error: {batch_error:.8f}")
    

if __name__ == "__main__":
    example_usage()
